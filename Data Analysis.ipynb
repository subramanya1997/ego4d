{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cf279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sreerag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\sreerag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\users\\sreerag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "#import \n",
    "from utils import *\n",
    "from utils.data_processing import Ego4d_NLQ\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d986f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913557a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetRoot = \"../fb-ego4d/ego4d_data/\" #\"./dataset/tmp/\"\n",
    "ego4d_json = dataSetRoot + \"ego4d.json\"\n",
    "v1_root = dataSetRoot + \"v1/\"\n",
    "annotation_root = v1_root + \"annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4D = Ego4d(ego4d_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b24536",
   "metadata": {},
   "outputs": [],
   "source": [
    "nql_train = annotation_root + \"nlq_train.json\"\n",
    "nql_val = annotation_root + \"nlq_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4e2cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train frames: 0\n",
      "#train clips: 0\n",
      "No Data Loaded!\n",
      "defaultdict(<class 'int'>, {})\n",
      "#train frames: 0\n",
      "#train clips: 0\n",
      "No Data Loaded!\n",
      "defaultdict(<class 'int'>, {})\n"
     ]
    }
   ],
   "source": [
    "nql_dataset_train = Ego4d_NLQ(nql_train)\n",
    "nql_dataset_val = Ego4d_NLQ(nql_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_train = annotation_root + \"vq_train.json\"\n",
    "vq_val = annotation_root + \"vq_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_dataset_train = Ego4d_VQ(vq_train)\n",
    "vq_dataset_val = Ego4d_VQ(vq_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4680e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_train = annotation_root + \"moments_train.json\"\n",
    "mq_val = annotation_root + \"moments_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474edd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_dataset_train = Ego4d_MQ(mq_train)\n",
    "mq_dataset_val = Ego4d_MQ(mq_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64072f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_train = annotation_root + \"vq_train.json\"\n",
    "vq_val = annotation_r#from collections import defaultdict\n",
    "video_clip_len = defaultdict(int)\n",
    "for _id, clip_ids in nql_dataset.video_clip.items():\n",
    "    secs = 0\n",
    "    for _c_id in clip_ids:\n",
    "        clip = nql_dataset.clips[_c_id]\n",
    "        secs += clip['video_end_sec'] - clip['video_start_sec']\n",
    "    video_clip_len[_id] = int(secs//60)\n",
    "video_clip_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a870436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "video_clip_val_len = defaultdict(int)\n",
    "for _id, clip_ids in nql_dataset_val.video_clip.items():\n",
    "    secs = 0\n",
    "    for _c_id in clip_ids:\n",
    "        clip = nql_dataset_val.clips[_c_id]\n",
    "        secs += clip['video_end_sec'] - clip['video_start_sec']\n",
    "    video_clip_val_len[_id] = int(secs//60)\n",
    "video_clip_val_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca84241",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = 0\n",
    "clip_length = 0\n",
    "for _id, m in video_clip_len.items():\n",
    "    video_length += video_len[_id]\n",
    "    clip_length += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad32216",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length_val = 0\n",
    "clip_length_val = 0\n",
    "for _id, m in video_clip_val_len.items():\n",
    "    video_length_val += video_len[_id]\n",
    "    clip_length_val += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9292dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_length//len(video_clip_len.keys()), clip_length//len(video_clip_len.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_length_val//len(video_clip_val_len.keys()), clip_length_val//len(video_clip_val_len.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe10ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clip_len_df = pd.DataFrame.from_dict(video_clip_len.items())\n",
    "video_len_df = pd.DataFrame.from_dict(video_len.items())\n",
    "print(video_clip_len_df.head())\n",
    "print(video_len_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fa486",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_len_df[video_clip_len_df[1] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6118def",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_clip_len_df[1].mean(), video_clip_len_df[1].max(), video_clip_len_df[1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clip_val_len_df = pd.DataFrame.from_dict(video_clip_val_len.items())\n",
    "video_len_df = pd.DataFrame.from_dict(video_len.items())\n",
    "print(video_clip_len_df.head())\n",
    "print(video_len_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_val_len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_val_len_df[video_clip_val_len_df[1] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_clip_val_len_df[1].mean(), video_clip_val_len_df[1].max(), video_clip_val_len_df[1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ego4D.videos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.videos.keys()), len(nql_dataset_val.videos.keys()), len(vq_dataset_train.videos.keys()), len(vq_dataset_val.videos.keys()), len(mq_dataset_train.videos.keys()), len(mq_dataset_val.videos.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.clips.keys()), len(nql_dataset_val.clips.keys()), len(vq_dataset_train.clips.keys()), len(vq_dataset_val.clips.keys()), len(mq_dataset_train.clips.keys()), len(mq_dataset_val.clips.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_video_train_ids = set(nql_dataset_train.videos.keys())\n",
    "nlq_video_val_ids = set(nql_dataset_val.videos.keys())\n",
    "vq_video_train_ids = set(vq_dataset_train.videos.keys())\n",
    "vq_video_val_ids = set(vq_dataset_val.videos.keys())\n",
    "mq_video_train_ids = set(mq_dataset_train.videos.keys())\n",
    "mq_video_val_ids = set(mq_dataset_val.videos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_union = nlq_video_train_ids.union(nlq_video_val_ids)\n",
    "vq_union = vq_video_train_ids.union(vq_video_val_ids)\n",
    "mq_union = mq_video_train_ids.union(mq_video_val_ids)\n",
    "\n",
    "print(len(nlq_union), len(vq_union), len(mq_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8031080",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_vq_mq_intersection = nlq_union.intersection(vq_union.intersection(mq_union))\n",
    "\n",
    "print(len(nlq_vq_mq_intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_sec = 0 \n",
    "audio_sec = 0\n",
    "video_duration = defaultdict(int)\n",
    "audio_duration = defaultdict(int)\n",
    "for _id in nlq_vq_mq_intersection:\n",
    "    duration_sec += ego4D.videos[_id]['duration_sec']\n",
    "    audio_sec += ego4D.videos[_id]['video_metadata']['audio_duration_sec'] if ego4D.videos[_id]['video_metadata']['audio_duration_sec'] != None else 0\n",
    "    video_duration[_id] = int(ego4D.videos[_id]['duration_sec']//60)\n",
    "    audio_duration[_id] = int((ego4D.videos[_id]['video_metadata']['audio_duration_sec'] if ego4D.videos[_id]['video_metadata']['audio_duration_sec'] != None else 0)//60)\n",
    "print( duration_sec//60, 'min,' ,duration_sec//3600, 'hr - of footage')\n",
    "print(duration_sec//len(nlq_vq_mq_intersection)//60, 'min - average length of video' )\n",
    "print( audio_sec//60, 'min,' ,audio_sec//3600, 'hr - of audio')\n",
    "print(audio_sec//len(nlq_vq_mq_intersection)//60, 'min - average length of video' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "videolength_df = pd.DataFrame.from_dict(video_duration.items())\n",
    "videolength_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732db61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiolength_df = pd.DataFrame.from_dict(audio_duration.items())\n",
    "audiolength_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0ddd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_len = 100\n",
    "print(videolength_df[1].sum(), audiolength_df[1].sum())\n",
    "print(len(videolength_df[videolength_df[1]<v_len]), len(videolength_df[videolength_df[1]>v_len]), \" less than : greater than \", videolength_df[videolength_df[1]<v_len][1].sum(), videolength_df[videolength_df[1]>v_len][1].sum(), \"min\")\n",
    "print(len(audiolength_df[videolength_df[1]<v_len]), len(audiolength_df[videolength_df[1]>v_len]), \" less than : greater than \", audiolength_df[videolength_df[1]<v_len][1].sum(), audiolength_df[videolength_df[1]>v_len][1].sum(), \"min\")\n",
    "print(\"Video and audio length are same: \",len(audiolength_df[audiolength_df[1] == videolength_df[1]]))\n",
    "temp_videolength_df = videolength_df[audiolength_df[1] == videolength_df[1]]\n",
    "print(temp_videolength_df[1].sum(), 'min')\n",
    "print(len(temp_videolength_df[temp_videolength_df[1]<v_len]), len(temp_videolength_df[temp_videolength_df[1]>v_len]), \" less than : greater than \" , temp_videolength_df[temp_videolength_df[1]<v_len][1].sum(), temp_videolength_df[temp_videolength_df[1]>v_len][1].sum(), \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameavlen_nlq_vq_mq_intersection = set(temp_videolength_df[0].to_numpy())\n",
    "sameavlen_nlq_vq_mq_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94956523",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "split = defaultdict(set)\n",
    "for _id in nlq_vq_mq_intersection:\n",
    "    for s in ego4D.videos[_id]['scenarios']:\n",
    "        scenarios[s].add(_id)\n",
    "    split[ego4D.videos[_id]['split_em']].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10328fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scenarios.keys()), scenarios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1542a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train: ',len(split['train']), 'val: ',len(split['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21efa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "split = defaultdict(set)\n",
    "for _id in sameavlen_nlq_vq_mq_intersection:\n",
    "    for s in ego4D.videos[_id]['scenarios']:\n",
    "        scenarios[s].add(_id)\n",
    "    split[ego4D.videos[_id]['split_em']].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scenarios.keys()), scenarios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train: ',len(split['train']), 'val: ',len(split['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameavlen_nlq_vq_mq_intersection = set(temp_videolength_df[temp_videolength_df[1]<v_len][0].to_numpy())\n",
    "#sameavlen_nlq_vq_mq_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "split = defaultdict(set)\n",
    "for _id in sameavlen_nlq_vq_mq_intersection:\n",
    "    for s in ego4D.videos[_id]['scenarios']:\n",
    "        scenarios[s].add(_id)\n",
    "    split[ego4D.videos[_id]['split_em']].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scenarios.keys()), scenarios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5426b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train: ',len(split['train']), 'val: ',len(split['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ''\n",
    "for i, s in enumerate(sameavlen_nlq_vq_mq_intersection):\n",
    "    ids += s\n",
    "    if i!= (len(sameavlen_nlq_vq_mq_intersection)-1):\n",
    "        ids += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./less_25.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "for i in list(sameavlen_nlq_vq_mq_intersection):\n",
    "    writer.writerow([i])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af698c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"./less_25.txt\",\"w\")\n",
    "file1.write(ids)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "for _id, v in ego4D.videos.items():\n",
    "    for s in v['scenarios']:\n",
    "        scenarios[s].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scenarios['Farmer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ''\n",
    "scenes = list(scenarios['Farmer'])[:10]\n",
    "for i, s in enumerate(scenes):\n",
    "    ids += s\n",
    "    if i!= (len(scenes)-1):\n",
    "        ids += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"./less_farming.txt\",\"w\")\n",
    "file1.write(ids)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498eb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = defaultdict(int)\n",
    "for i, v in ego4D.videos.items():\n",
    "    audio[i] = v['video_metadata']['audio_duration_sec']\n",
    "\n",
    "audio_df = pd.DataFrame.from_dict(audio.items())\n",
    "audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8894c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nql_dataset_train.clips['fae92e70-88aa-4b77-b41a-5879b74c804c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4640549",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipAudio_nlq_train = set()\n",
    "for _id, c in nql_dataset_train.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if nql_dataset_train.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[nql_dataset_train.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_nlq_train.add(_id)\n",
    "\n",
    "clipAudio_nlq_val = set()\n",
    "for _id, c in nql_dataset_val.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if nql_dataset_val.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[nql_dataset_val.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_nlq_val.add(_id)\n",
    "\n",
    "clipAudio_vq_train = set()\n",
    "for _id, c in vq_dataset_train.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if vq_dataset_train.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[vq_dataset_train.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_vq_train.add(_id)\n",
    "\n",
    "clipAudio_vq_val = set()            \n",
    "for _id, c in vq_dataset_val.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if vq_dataset_val.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[vq_dataset_val.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_vq_val.add(_id)\n",
    "\n",
    "clipAudio_mq_train = set()\n",
    "for _id, c in mq_dataset_train.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if mq_dataset_train.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[mq_dataset_train.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_mq_train.add(_id)\n",
    "        \n",
    "clipAudio_mq_val = set()\n",
    "for _id, c in mq_dataset_val.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if mq_dataset_val.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[mq_dataset_val.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_mq_val.add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.clips.keys()), len(nql_dataset_val.clips.keys()), len(clipAudio_nlq_train),len(clipAudio_nlq_val) )\n",
    "print(len(vq_dataset_train.clips.keys()), len(vq_dataset_val.clips.keys()), len(clipAudio_vq_train), len(clipAudio_vq_val))\n",
    "print(len(mq_dataset_train.clips.keys()), len(mq_dataset_val.clips.keys()), len(clipAudio_mq_train), len(clipAudio_mq_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_nql_train = set()\n",
    "for _id in clipAudio_nlq_train:\n",
    "    video_ids_nql_train.add(nql_dataset_train.clip_video[_id])\n",
    "\n",
    "video_ids_nql_val = set()\n",
    "for _id in clipAudio_nlq_val:\n",
    "    video_ids_nql_val.add(nql_dataset_val.clip_video[_id])\n",
    "    \n",
    "video_ids_vq_train = set()\n",
    "for _id in clipAudio_vq_train:\n",
    "    video_ids_vq_train.add(vq_dataset_train.clip_video[_id])\n",
    "    \n",
    "video_ids_vq_val = set()\n",
    "for _id in clipAudio_vq_val:\n",
    "    video_ids_vq_val.add(vq_dataset_val.clip_video[_id])\n",
    "    \n",
    "video_ids_mq_train = set()\n",
    "for _id in clipAudio_mq_train:\n",
    "    video_ids_mq_train.add(mq_dataset_train.clip_video[_id])\n",
    "    \n",
    "video_ids_mq_val = set()\n",
    "for _id in clipAudio_mq_val:\n",
    "    video_ids_mq_val.add(mq_dataset_val.clip_video[_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.videos.keys()),len(nql_dataset_val.videos.keys()),len(vq_dataset_train.videos.keys()),len(vq_dataset_val.videos.keys()),len(mq_dataset_train.videos.keys()),len(mq_dataset_val.videos.keys()))\n",
    "print(len(video_ids_nql_train),len(video_ids_nql_val),len(video_ids_vq_train),len(video_ids_vq_val),len(video_ids_mq_train),len(video_ids_mq_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ba669",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_union = video_ids_nql_train.union(video_ids_nql_val)\n",
    "vq_union = video_ids_vq_train.union(video_ids_vq_val)\n",
    "mq_union = video_ids_mq_train.union(video_ids_mq_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nlq_union), len(vq_union),len(mq_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d85c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_vq_mq = nlq_union.intersection(vq_union.intersection(mq_union))\n",
    "len(nlq_vq_mq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_nql_union = clipAudio_nlq_train.union(clipAudio_nlq_val)\n",
    "clip_vq_union = clipAudio_vq_train.union(clipAudio_vq_val)\n",
    "clip_mq_union = clipAudio_mq_train.union(clipAudio_mq_val)\n",
    "print(len(clip_nql_union), len(clip_vq_union), len(clip_mq_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_nlq_vq_mq = clip_nql_union.union(clip_vq_union.union(clip_mq_union))\n",
    "len(clip_nlq_vq_mq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips = defaultdict(set)\n",
    "for _id in clipAudio_nlq_train:\n",
    "    idx = nql_dataset_train.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_nlq_val:\n",
    "    idx = nql_dataset_val.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_vq_train:\n",
    "    idx = vq_dataset_train.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_vq_val:\n",
    "    idx = vq_dataset_val.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_mq_train:\n",
    "    idx = mq_dataset_train.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "    \n",
    "for _id in clipAudio_mq_val:\n",
    "    idx = mq_dataset_val.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3680cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips_df = pd.DataFrame.from_dict(video_clips.items())\n",
    "video_clips_df['Length'] = video_clips_df[1].str.len()\n",
    "video_clips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = video_clips_df.plot.bar( y='Length', rot=0, figsize=(30, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips_3 = video_clips_df[video_clips_df['Length'] <= 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18624bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ''\n",
    "for i, s in enumerate(sameavlen_nlq_vq_mq_intersection):\n",
    "    ids += s\n",
    "    if i!= (len(sameavlen_nlq_vq_mq_intersection)-1):\n",
    "        ids += ' '\n",
    "for i, c in enumerate(video_clips_3[1]):\n",
    "    for j, _id in enumerate(c):\n",
    "        ids += _id\n",
    "        if i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"./less_3.txt\",\"w\")\n",
    "file1.write(ids)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with av.open(clips_path) as input_video:\n",
    "    stream = input_video.streams.audio\n",
    "    print(stream)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd145cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_path = v1_root + 'clips/1c6f2ab7-1088-45d6-b172-8bbd2ded74ac.mp4'\n",
    "my_clip = mp.VideoFileClip(clips_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clip.audio.write_audiofile(r\"my_result.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd59823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68be5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = defaultdict(str)\n",
    "for root, dirs, files in os.walk(\"./dataset/tmp/v1/clips/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            file_paths[file.split('.')[0]] = os.path.join(root, file)\n",
    "            \n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b96ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "MoviePy couldn't find the codec associated with the filename. Provide the 'codec' parameter in write_audiofile.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs682/lib/python3.8/site-packages/moviepy/audio/AudioClip.py:200\u001b[0m, in \u001b[0;36mAudioClip.write_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     codec \u001b[38;5;241m=\u001b[39m \u001b[43mextensions_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mext\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextractAudioFromClips\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Data/research/ego4d/utils.py:23\u001b[0m, in \u001b[0;36mextractAudioFromClips\u001b[0;34m(video_path, audio_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _filename, _path \u001b[38;5;129;01min\u001b[39;00m file_paths\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     22\u001b[0m     _clip \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mVideoFileClip(_path)\n\u001b[0;32m---> 23\u001b[0m     \u001b[43m_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_audiofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-62>:2\u001b[0m, in \u001b[0;36mwrite_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs682/lib/python3.8/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs682/lib/python3.8/site-packages/moviepy/audio/AudioClip.py:202\u001b[0m, in \u001b[0;36mAudioClip.write_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n\u001b[1;32m    200\u001b[0m         codec \u001b[38;5;241m=\u001b[39m extensions_dict[ext[\u001b[38;5;241m1\u001b[39m:]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoviePy couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find the codec associated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the filename. Provide the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter in write_audiofile.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ffmpeg_audiowrite(\u001b[38;5;28mself\u001b[39m, filename, fps, nbytes, buffersize,\n\u001b[1;32m    207\u001b[0m                          codec\u001b[38;5;241m=\u001b[39mcodec, bitrate\u001b[38;5;241m=\u001b[39mbitrate,\n\u001b[1;32m    208\u001b[0m                          write_logfile\u001b[38;5;241m=\u001b[39mwrite_logfile, verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    209\u001b[0m                          ffmpeg_params\u001b[38;5;241m=\u001b[39mffmpeg_params,\n\u001b[1;32m    210\u001b[0m                          logger\u001b[38;5;241m=\u001b[39mlogger)\n",
      "\u001b[0;31mValueError\u001b[0m: MoviePy couldn't find the codec associated with the filename. Provide the 'codec' parameter in write_audiofile."
     ]
    }
   ],
   "source": [
    "extractAudioFromClips()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-application",
   "metadata": {},
   "source": [
    "### NLQ template queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "false-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemplateCounts(nlq_dataset):\n",
    "    json_data = nlq_dataset.raw_data_formatted\n",
    "    query_templates = list(map(lambda a : (a[0], a[1][\"query_templates\"]), json_data.items()))\n",
    "    query_templates_arr = list(map(lambda a : a[1], query_templates))\n",
    "    flat_query_templates = list(np.concatenate(query_templates_arr).flat)\n",
    "    return Counter(flat_query_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "finite-juvenile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Objects: Where is object X before / after event Y?', 1760),\n",
       " ('Place: Where did I put X?', 1676),\n",
       " ('Objects: Where is object X?', 1455),\n",
       " ('Objects: What did I put in X?', 1263),\n",
       " ('Objects: How many X’s? (quantity question)', 967),\n",
       " ('Objects: In what location did I see object X ?', 922),\n",
       " ('Objects: What X did I Y?', 878),\n",
       " ('Objects: What X is Y?', 853),\n",
       " ('Objects: State of an object', 569),\n",
       " ('People: Who did I interact with when I did activity X?', 298),\n",
       " ('Objects: Where is my object X?', 261),\n",
       " ('People: Who did I talk to in location X?', 224),\n",
       " ('People: When did I talk to or interact with person with role X?', 103),\n",
       " (None, 62)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts of query templates in NLQ train set\n",
    "unique_templates = getTemplateCounts(nql_dataset_train)\n",
    "unique_templates.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "technological-eating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Objects: Where is object X before / after event Y?', 644),\n",
       " ('Place: Where did I put X?', 626),\n",
       " ('Objects: What did I put in X?', 476),\n",
       " ('Objects: Where is object X?', 447),\n",
       " ('Objects: What X did I Y?', 312),\n",
       " ('Objects: What X is Y?', 306),\n",
       " ('Objects: How many X’s? (quantity question)', 300),\n",
       " ('Objects: In what location did I see object X ?', 293),\n",
       " ('Objects: State of an object', 168),\n",
       " ('People: Who did I interact with when I did activity X?', 102),\n",
       " ('People: Who did I talk to in location X?', 83),\n",
       " ('Objects: Where is my object X?', 77),\n",
       " ('People: When did I talk to or interact with person with role X?', 25),\n",
       " (None, 15)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts of query templates in NLQ val set\n",
    "unique_templates_val = getTemplateCounts(nql_dataset_val)\n",
    "unique_templates_val.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "boring-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which queries have no templates\n",
    "def getNullTemplateData(nlq_dataset):\n",
    "    json_data = nlq_dataset.raw_data_formatted\n",
    "    no_templates = []\n",
    "    for k,v in json_data.items():\n",
    "        for q, qt in zip(v[\"sentences\"], v[\"query_templates\"]):\n",
    "            if qt == None:\n",
    "                no_templates.append((k, q))\n",
    "    return no_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-melissa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the clip id and query when there is no template in NLQ train set\n",
    "getNullTemplateData(nql_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "early-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('77a2e39b-4982-4c53-9a98-e9c7708721c6',\n",
       "  'where did i put the box with wooden tiles?'),\n",
       " ('e0b0ee85-ad8f-47de-ba8b-35c147d84f1c', 'who did i talk to in the house?'),\n",
       " ('e0b0ee85-ad8f-47de-ba8b-35c147d84f1c',\n",
       "  'who did i interact with  while walking in the house?'),\n",
       " ('b66e0c62-810f-40ba-a453-050fe752ea67',\n",
       "  'where was the glass jug before i picked it up?'),\n",
       " ('0ad00ff1-054b-4843-ba3a-8fda76311e0c', 'where did i put the hat?'),\n",
       " ('4b128b10-8af3-40c9-bd92-4bedb8a0ab82',\n",
       "  'what numbers did i see on the oven screen?'),\n",
       " ('64571a50-3433-4002-9de9-be6d5ded11a7',\n",
       "  'in what location did i see the tissue paper?'),\n",
       " ('64571a50-3433-4002-9de9-be6d5ded11a7', 'where is the phone?'),\n",
       " ('acc040c0-82ed-4a79-8f12-759477b5775a', 'where did i pour the dirty water?'),\n",
       " ('5e5656d7-83d3-45db-8f97-601328801fd5', 'where did i dispose cabbage?'),\n",
       " ('483ddc10-9c9b-4dc7-97fc-86fba1033361',\n",
       "  'where was the circular saw before i moved it?'),\n",
       " ('04c23dbd-f207-4359-a9d7-a10669c4938e',\n",
       "  'where did i drop the cup after i picked it ?'),\n",
       " ('a28e44f3-4a26-491f-9ca1-524d40c863c0',\n",
       "  'in what location did i see the air conditioner?'),\n",
       " ('641d7201-0d66-4c84-8759-bac89d8f5b73', 'how manty blue plates did i see?'),\n",
       " ('641d7201-0d66-4c84-8759-bac89d8f5b73',\n",
       "  'in what location did i see the white bucket?'),\n",
       " ('641d7201-0d66-4c84-8759-bac89d8f5b73',\n",
       "  'in what location did i see pot lid?'),\n",
       " ('3bd41be7-8d08-4d83-b0ad-d066bb96f147', 'what color is the throw pillow?'),\n",
       " ('9dd8f049-2eba-490b-bdc0-8b4d64719348',\n",
       "  'how much salt did i put in the bowl.?'),\n",
       " ('9dd8f049-2eba-490b-bdc0-8b4d64719348',\n",
       "  'how many spoons of oil did i put in the bowl.?'),\n",
       " ('3e310620-c894-4f65-b3ff-6c91e71e7d15', 'where is the piano?'),\n",
       " ('f4331a0a-fb63-4747-8f1f-f7e785eb8f08', 'where did i put the ladder?'),\n",
       " ('8c3b46d9-bb70-4f1b-93dd-1758ca739c20',\n",
       "  'where was the phone before i moved it?'),\n",
       " ('4fe41d16-9136-4d81-bd5c-071018baaba4',\n",
       "  'where was the scissors before i took it?'),\n",
       " ('4fe41d16-9136-4d81-bd5c-071018baaba4',\n",
       "  'where was the black tape before i picked it?'),\n",
       " ('4fe41d16-9136-4d81-bd5c-071018baaba4', 'how many toolboxes did i see?'),\n",
       " ('4fba410d-405a-4265-a886-a1c9d589c007', 'where is the white car?'),\n",
       " ('a52b0470-1bbf-4398-828c-26f9911d481d',\n",
       "  'where was the pot before i picked it?'),\n",
       " ('a52b0470-1bbf-4398-828c-26f9911d481d', 'what did i put in the bin?'),\n",
       " ('fe6e4e62-208b-475b-8c52-6bc93f943679', 'where did i put the black tray?'),\n",
       " ('2f53646d-439d-4603-aa22-9bc43ca6547e',\n",
       "  'when did i shake the mountain climber?'),\n",
       " ('d5c8c96c-7653-4ff7-909b-3ec1fea2e4bb', 'what color is the keg i kicked?'),\n",
       " ('8dfe640e-b129-469f-aca3-36e4c5ec8184',\n",
       "  'where was the knife before i pulled the drawer?'),\n",
       " ('29504fb8-96bb-4376-bca6-c1949496154d', 'where did i grab the wood filler?'),\n",
       " ('2b38433a-a221-430e-ad08-8ca1f874d94d',\n",
       "  'in which side of the store did i see the weighing machine?'),\n",
       " ('2b38433a-a221-430e-ad08-8ca1f874d94d',\n",
       "  'who did i talk to when i put the basket on the counter?'),\n",
       " ('9f937462-0c26-49f4-af3e-07443ae601e6',\n",
       "  'where was the bottle of oil before i picked it?'),\n",
       " ('f1e90149-6907-40ca-b272-7f9652a8b775', 'what did i put in the bucket?'),\n",
       " ('569e69fa-3fd9-410d-86cf-64a590dd0946',\n",
       "  'where was the cabbage before i picked it up?'),\n",
       " ('f6b9e636-873f-4deb-8a7c-c38708f0a9c9',\n",
       "  'in what location can i see the cloth hanger last?'),\n",
       " ('9b574ee2-ef1f-4ed8-92b0-ba88f993ddf3', 'what nylon did i cut?'),\n",
       " ('13b398f0-3465-4103-8878-a22e4f771b7f', 'where is the television placed?'),\n",
       " ('bae0f81c-3e52-4cfc-81b5-9f028c4f3681',\n",
       "  'what color was the clipped card on the refrigerator?'),\n",
       " ('bae0f81c-3e52-4cfc-81b5-9f028c4f3681',\n",
       "  'what color was the cloth on the door?'),\n",
       " ('19787ac8-3172-428f-8598-f06f84e188b8',\n",
       "  'where was the storage bin before i picked it?'),\n",
       " ('d7932db7-752a-4437-b7f3-25fa9d094de7',\n",
       "  'in what location did i see the maroon blouse on the dummy?'),\n",
       " ('dc2a7a91-8c8c-4385-a7af-6387ce887d65',\n",
       "  'in what location did i see the scarf?'),\n",
       " ('1c30358a-0f74-42aa-ab6c-c02e771d204b',\n",
       "  'what color is the napkin i cleaned the steel flask with?'),\n",
       " ('e09f77af-c979-458d-b2e9-54bb656a6586',\n",
       "  'where was the wire before i held it?'),\n",
       " ('2621b9a5-d9c6-4827-bc25-80b2e1e822df',\n",
       "  'where was the pot before i removed it?'),\n",
       " ('a560c5ad-57ce-431e-a49c-298ebefaf892',\n",
       "  'in what location did i see the fire hydrant?'),\n",
       " ('3e488b02-b613-4a29-ba79-6b4bd0951ef0',\n",
       "  'how many pillows were on the sofa?'),\n",
       " ('ec2d62e8-5993-4085-b65b-3f70e063862c', 'did i close the cabinet?'),\n",
       " ('cd08667f-ac7c-4425-acdd-5970240ff8b3',\n",
       "  'where was the plumber wrench before i picked it?'),\n",
       " ('89c3bb6f-0c87-4f26-aaff-740f8311a245',\n",
       "  'in what location did i see the yellow lift?'),\n",
       " ('1e4b1994-ea56-429c-a22d-d377a864363a',\n",
       "  'what words were written on the wall art?'),\n",
       " ('a742829d-cf1e-4f66-b982-0b1ada88a26e',\n",
       "  'in what location did i see brake spring pliers?'),\n",
       " ('10f997d1-df06-4e96-bafd-06e60872e1b2',\n",
       "  'where was the hand drill before i picked it up?'),\n",
       " ('10f997d1-df06-4e96-bafd-06e60872e1b2',\n",
       "  'what did i put in the paint bucket?'),\n",
       " ('daf6d9fe-bead-48dc-b52a-df42203c896f',\n",
       "  'where was the hand drill before i picked it?'),\n",
       " ('68fbe8ef-3a20-421d-a66c-c3e2578c371f', 'what did i put under the basket?'),\n",
       " ('63bb3615-b377-4e49-9b0b-5bbb6809c320', 'how many cups were on the table?'),\n",
       " ('d2c5b90e-4925-4535-8afc-d578ff79f32c',\n",
       "  'where was the hammer before washing the paint brush in a container?')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data = nql_dataset_train.raw_data_formatted\n",
    "no_templates = []\n",
    "for k,v in json_data.items():\n",
    "    for q, qt in zip(v[\"sentences\"], v[\"query_templates\"]):\n",
    "        if qt == None:\n",
    "            no_templates.append((k, q))\n",
    "no_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dba139fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extraordinary-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = mp.VideoFileClip(\"/scratch/snagabhushan_umass_edu/dataset/v1/clips/000eba33-8d14-446a-b016-19bd50e9a3b9.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fb63058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47089, 1024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_features = torch.load(\"/scratch/snagabhushan_umass_edu/dataset/v1/audio_features/000eba33-8d14-446a-b016-19bd50e9a3b9.pt\")\n",
    "audio_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e09f99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([901, 2304])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.load(\"/scratch/shantanuagar_umass_edu/ego4d/saved_clip_features/000eba33-8d14-446a-b016-19bd50e9a3b9.pt\")\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aac79498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14401it [02:40, 89.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[86 79 79]\n",
      "  [86 79 79]\n",
      "  [87 80 80]\n",
      "  ...\n",
      "  [68 66 62]\n",
      "  [68 66 62]\n",
      "  [68 66 62]]\n",
      "\n",
      " [[86 79 79]\n",
      "  [86 79 79]\n",
      "  [87 80 80]\n",
      "  ...\n",
      "  [68 66 62]\n",
      "  [68 66 62]\n",
      "  [68 66 62]]\n",
      "\n",
      " [[86 79 79]\n",
      "  [86 79 79]\n",
      "  [87 80 80]\n",
      "  ...\n",
      "  [68 66 62]\n",
      "  [68 66 62]\n",
      "  [68 66 62]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[27 25 26]\n",
      "  [27 25 26]\n",
      "  [27 25 26]\n",
      "  ...\n",
      "  [71 46 16]\n",
      "  [71 46 16]\n",
      "  [71 46 16]]\n",
      "\n",
      " [[24 22 23]\n",
      "  [24 22 23]\n",
      "  [24 22 23]\n",
      "  ...\n",
      "  [71 46 16]\n",
      "  [71 46 16]\n",
      "  [71 46 16]]\n",
      "\n",
      " [[24 22 23]\n",
      "  [24 22 23]\n",
      "  [24 22 23]\n",
      "  ...\n",
      "  [71 46 16]\n",
      "  [71 46 16]\n",
      "  [71 46 16]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "j = 0 \n",
    "for i, frame in tqdm(enumerate(video.iter_frames())):\n",
    "    j = i\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2bf4ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.263041065482795"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47089 / 901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8982c",
   "metadata": {},
   "source": [
    "### sampling ego4d.json for NLQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f546654",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4d_json = None\n",
    "with open(r'S:\\umass\\696ds\\fb-ego4d\\ego4d_data\\ego4d.json','r') as f:\n",
    "    ego4d_json = json.load(f)\n",
    "def sampleNLQEgo4d(filepath):\n",
    "    nlq_json = None\n",
    "    with open(filepath,'r') as f:\n",
    "        nlq_json = json.load(f)\n",
    "    nlq_vids = nlq_json['videos']\n",
    "    nlq_vids_ids = list(map(lambda a : a['video_uid'], nlq_vids))\n",
    "    return list(filter(lambda a : nlq_vids_ids.count(a['video_uid'])>0, ego4d_json['videos']))\n",
    "vid_train = sampleNLQEgo4d(r'S:\\umass\\696ds\\fb-ego4d\\sample_nlq_train.json')\n",
    "vid_val = sampleNLQEgo4d(r'S:\\umass\\696ds\\fb-ego4d\\sample_nlq_test.json')\n",
    "vid_test = sampleNLQEgo4d(r'S:\\umass\\696ds\\fb-ego4d\\sample_nlq_val.json')\n",
    "train_json = deepcopy(ego4d_json)\n",
    "val_json = deepcopy(ego4d_json)\n",
    "test_json = deepcopy(ego4d_json)\n",
    "train_json['videos'] = vid_train\n",
    "test_json['videos'] = vid_test\n",
    "val_json['videos'] = vid_val\n",
    "ego4d_json['videos'] = vid_train+vid_test+vid_val\n",
    "with open(r'S:\\umass\\696ds\\ego4d\\sample_ego4d_train.json','w') as f:\n",
    "    json.dump(train_json, f)\n",
    "with open(r'S:\\umass\\696ds\\ego4d\\sample_ego4d_test.json','w') as f:\n",
    "    json.dump(test_json, f)\n",
    "with open(r'S:\\umass\\696ds\\ego4d\\sample_ego4d_val.json','w') as f:\n",
    "    json.dump(val_json, f)\n",
    "with open(r'S:\\umass\\696ds\\ego4d\\sample_ego4d.json','w') as f:\n",
    "    json.dump(ego4d_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67105d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'S:\\umass\\696ds\\fb-ego4d\\ego4d_data\\v1\\annotations\\narration.json','r') as f:\n",
    "    print(f.read(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f9fae",
   "metadata": {},
   "source": [
    "### video + narrations json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e2e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import MEMEDataLoader\n",
    "ego4d_path = r'S:\\umass\\696ds\\ego4d\\sample_ego4d.json'\n",
    "narr_path = r'S:\\umass\\696ds\\fb-ego4d\\ego4d_data\\v1\\annotations\\narration.json'\n",
    "dl_obj = MEMEDataLoader(json_path=ego4d_path, narrations_path=narr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686c908",
   "metadata": {},
   "source": [
    "### MQ Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing_mq import Ego4d_MQ\n",
    "mq_dl = Ego4d_MQ(r'S:\\umass\\696ds\\fb-ego4d\\ego4d_data\\v1\\annotations\\moments_val.json', save_or_load_path=r'S:\\umass\\696ds\\mq_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_dl.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50628387",
   "metadata": {},
   "source": [
    "### VQ Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72402ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing_vq import Ego4d_VQ\n",
    "vq_dl = Ego4d_VQ(r'S:\\umass\\696ds\\fb-ego4d\\ego4d_data\\v1\\annotations\\vq_val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824b8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
