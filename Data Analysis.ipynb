{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cf279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "from utils import *\n",
    "from data_processing import Ego4d, Ego4d_NQL, Ego4d_VQ, Ego4d_MQ\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913557a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetRoot = \"./dataset/tmp/\"\n",
    "ego4d_json = dataSetRoot + \"ego4d.json\"\n",
    "v1_root = dataSetRoot + \"v1/\"\n",
    "annotation_root = v1_root + \"annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4D = Ego4d(ego4d_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b24536",
   "metadata": {},
   "outputs": [],
   "source": [
    "nql_train = annotation_root + \"nlq_train.json\"\n",
    "nql_val = annotation_root + \"nlq_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e2cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nql_dataset_train = Ego4d_NQL(nql_train)\n",
    "nql_dataset_val = Ego4d_NQL(nql_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_train = annotation_root + \"vq_train.json\"\n",
    "vq_val = annotation_root + \"vq_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_dataset_train = Ego4d_VQ(vq_train)\n",
    "vq_dataset_val = Ego4d_VQ(vq_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4680e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_train = annotation_root + \"moments_train.json\"\n",
    "mq_val = annotation_root + \"moments_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474edd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_dataset_train = Ego4d_MQ(mq_train)\n",
    "mq_dataset_val = Ego4d_MQ(mq_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64072f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "video_clip_len = defaultdict(int)\n",
    "for _id, clip_ids in nql_dataset.video_clip.items():\n",
    "    secs = 0\n",
    "    for _c_id in clip_ids:\n",
    "        clip = nql_dataset.clips[_c_id]\n",
    "        secs += clip['video_end_sec'] - clip['video_start_sec']\n",
    "    video_clip_len[_id] = int(secs//60)\n",
    "video_clip_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a870436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import defaultdict\n",
    "video_clip_val_len = defaultdict(int)\n",
    "for _id, clip_ids in nql_dataset_val.video_clip.items():\n",
    "    secs = 0\n",
    "    for _c_id in clip_ids:\n",
    "        clip = nql_dataset_val.clips[_c_id]\n",
    "        secs += clip['video_end_sec'] - clip['video_start_sec']\n",
    "    video_clip_val_len[_id] = int(secs//60)\n",
    "video_clip_val_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca84241",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = 0\n",
    "clip_length = 0\n",
    "for _id, m in video_clip_len.items():\n",
    "    video_length += video_len[_id]\n",
    "    clip_length += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad32216",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length_val = 0\n",
    "clip_length_val = 0\n",
    "for _id, m in video_clip_val_len.items():\n",
    "    video_length_val += video_len[_id]\n",
    "    clip_length_val += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9292dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_length//len(video_clip_len.keys()), clip_length//len(video_clip_len.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_length_val//len(video_clip_val_len.keys()), clip_length_val//len(video_clip_val_len.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe10ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clip_len_df = pd.DataFrame.from_dict(video_clip_len.items())\n",
    "video_len_df = pd.DataFrame.from_dict(video_len.items())\n",
    "print(video_clip_len_df.head())\n",
    "print(video_len_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fa486",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_len_df[video_clip_len_df[1] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6118def",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_clip_len_df[1].mean(), video_clip_len_df[1].max(), video_clip_len_df[1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clip_val_len_df = pd.DataFrame.from_dict(video_clip_val_len.items())\n",
    "video_len_df = pd.DataFrame.from_dict(video_len.items())\n",
    "print(video_clip_len_df.head())\n",
    "print(video_len_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_val_len_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_clip_val_len_df[video_clip_val_len_df[1] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_clip_val_len_df[1].mean(), video_clip_val_len_df[1].max(), video_clip_val_len_df[1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ego4D.videos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.videos.keys()), len(nql_dataset_val.videos.keys()), len(vq_dataset_train.videos.keys()), len(vq_dataset_val.videos.keys()), len(mq_dataset_train.videos.keys()), len(mq_dataset_val.videos.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.clips.keys()), len(nql_dataset_val.clips.keys()), len(vq_dataset_train.clips.keys()), len(vq_dataset_val.clips.keys()), len(mq_dataset_train.clips.keys()), len(mq_dataset_val.clips.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_video_train_ids = set(nql_dataset_train.videos.keys())\n",
    "nlq_video_val_ids = set(nql_dataset_val.videos.keys())\n",
    "vq_video_train_ids = set(vq_dataset_train.videos.keys())\n",
    "vq_video_val_ids = set(vq_dataset_val.videos.keys())\n",
    "mq_video_train_ids = set(mq_dataset_train.videos.keys())\n",
    "mq_video_val_ids = set(mq_dataset_val.videos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_union = nlq_video_train_ids.union(nlq_video_val_ids)\n",
    "vq_union = vq_video_train_ids.union(vq_video_val_ids)\n",
    "mq_union = mq_video_train_ids.union(mq_video_val_ids)\n",
    "\n",
    "print(len(nlq_union), len(vq_union), len(mq_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8031080",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_vq_mq_intersection = nlq_union.intersection(vq_union.intersection(mq_union))\n",
    "\n",
    "print(len(nlq_vq_mq_intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_sec = 0 \n",
    "audio_sec = 0\n",
    "video_duration = defaultdict(int)\n",
    "audio_duration = defaultdict(int)\n",
    "for _id in nlq_vq_mq_intersection:\n",
    "    duration_sec += ego4D.videos[_id]['duration_sec']\n",
    "    audio_sec += ego4D.videos[_id]['video_metadata']['audio_duration_sec'] if ego4D.videos[_id]['video_metadata']['audio_duration_sec'] != None else 0\n",
    "    video_duration[_id] = int(ego4D.videos[_id]['duration_sec']//60)\n",
    "    audio_duration[_id] = int((ego4D.videos[_id]['video_metadata']['audio_duration_sec'] if ego4D.videos[_id]['video_metadata']['audio_duration_sec'] != None else 0)//60)\n",
    "print( duration_sec//60, 'min,' ,duration_sec//3600, 'hr - of footage')\n",
    "print(duration_sec//len(nlq_vq_mq_intersection)//60, 'min - average length of video' )\n",
    "print( audio_sec//60, 'min,' ,audio_sec//3600, 'hr - of audio')\n",
    "print(audio_sec//len(nlq_vq_mq_intersection)//60, 'min - average length of video' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "videolength_df = pd.DataFrame.from_dict(video_duration.items())\n",
    "videolength_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732db61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiolength_df = pd.DataFrame.from_dict(audio_duration.items())\n",
    "audiolength_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0ddd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_len = 100\n",
    "print(videolength_df[1].sum(), audiolength_df[1].sum())\n",
    "print(len(videolength_df[videolength_df[1]<v_len]), len(videolength_df[videolength_df[1]>v_len]), \" less than : greater than \", videolength_df[videolength_df[1]<v_len][1].sum(), videolength_df[videolength_df[1]>v_len][1].sum(), \"min\")\n",
    "print(len(audiolength_df[videolength_df[1]<v_len]), len(audiolength_df[videolength_df[1]>v_len]), \" less than : greater than \", audiolength_df[videolength_df[1]<v_len][1].sum(), audiolength_df[videolength_df[1]>v_len][1].sum(), \"min\")\n",
    "print(\"Video and audio length are same: \",len(audiolength_df[audiolength_df[1] == videolength_df[1]]))\n",
    "temp_videolength_df = videolength_df[audiolength_df[1] == videolength_df[1]]\n",
    "print(temp_videolength_df[1].sum(), 'min')\n",
    "print(len(temp_videolength_df[temp_videolength_df[1]<v_len]), len(temp_videolength_df[temp_videolength_df[1]>v_len]), \" less than : greater than \" , temp_videolength_df[temp_videolength_df[1]<v_len][1].sum(), temp_videolength_df[temp_videolength_df[1]>v_len][1].sum(), \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameavlen_nlq_vq_mq_intersection = set(temp_videolength_df[0].to_numpy())\n",
    "sameavlen_nlq_vq_mq_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94956523",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "split = defaultdict(set)\n",
    "for _id in nlq_vq_mq_intersection:\n",
    "    for s in ego4D.videos[_id]['scenarios']:\n",
    "        scenarios[s].add(_id)\n",
    "    split[ego4D.videos[_id]['split_em']].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10328fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scenarios.keys()), scenarios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1542a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train: ',len(split['train']), 'val: ',len(split['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21efa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "split = defaultdict(set)\n",
    "for _id in sameavlen_nlq_vq_mq_intersection:\n",
    "    for s in ego4D.videos[_id]['scenarios']:\n",
    "        scenarios[s].add(_id)\n",
    "    split[ego4D.videos[_id]['split_em']].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scenarios.keys()), scenarios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train: ',len(split['train']), 'val: ',len(split['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "sameavlen_nlq_vq_mq_intersection = set(temp_videolength_df[temp_videolength_df[1]<v_len][0].to_numpy())\n",
    "#sameavlen_nlq_vq_mq_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "split = defaultdict(set)\n",
    "for _id in sameavlen_nlq_vq_mq_intersection:\n",
    "    for s in ego4D.videos[_id]['scenarios']:\n",
    "        scenarios[s].add(_id)\n",
    "    split[ego4D.videos[_id]['split_em']].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scenarios.keys()), scenarios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5426b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train: ',len(split['train']), 'val: ',len(split['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ''\n",
    "for i, s in enumerate(sameavlen_nlq_vq_mq_intersection):\n",
    "    ids += s\n",
    "    if i!= (len(sameavlen_nlq_vq_mq_intersection)-1):\n",
    "        ids += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./less_25.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "for i in list(sameavlen_nlq_vq_mq_intersection):\n",
    "    writer.writerow([i])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af698c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"./less_25.txt\",\"w\")\n",
    "file1.write(ids)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = defaultdict(set)\n",
    "for _id, v in ego4D.videos.items():\n",
    "    for s in v['scenarios']:\n",
    "        scenarios[s].add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scenarios['Farmer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ''\n",
    "scenes = list(scenarios['Farmer'])[:10]\n",
    "for i, s in enumerate(scenes):\n",
    "    ids += s\n",
    "    if i!= (len(scenes)-1):\n",
    "        ids += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"./less_farming.txt\",\"w\")\n",
    "file1.write(ids)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498eb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = defaultdict(int)\n",
    "for i, v in ego4D.videos.items():\n",
    "    audio[i] = v['video_metadata']['audio_duration_sec']\n",
    "\n",
    "audio_df = pd.DataFrame.from_dict(audio.items())\n",
    "audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8894c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nql_dataset_train.clips['fae92e70-88aa-4b77-b41a-5879b74c804c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4640549",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipAudio_nlq_train = set()\n",
    "for _id, c in nql_dataset_train.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if nql_dataset_train.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[nql_dataset_train.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_nlq_train.add(_id)\n",
    "\n",
    "clipAudio_nlq_val = set()\n",
    "for _id, c in nql_dataset_val.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if nql_dataset_val.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[nql_dataset_val.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_nlq_val.add(_id)\n",
    "\n",
    "clipAudio_vq_train = set()\n",
    "for _id, c in vq_dataset_train.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if vq_dataset_train.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[vq_dataset_train.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_vq_train.add(_id)\n",
    "\n",
    "clipAudio_vq_val = set()            \n",
    "for _id, c in vq_dataset_val.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if vq_dataset_val.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[vq_dataset_val.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_vq_val.add(_id)\n",
    "\n",
    "clipAudio_mq_train = set()\n",
    "for _id, c in mq_dataset_train.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if mq_dataset_train.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[mq_dataset_train.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_mq_train.add(_id)\n",
    "        \n",
    "clipAudio_mq_val = set()\n",
    "for _id, c in mq_dataset_val.clips.items():\n",
    "        videoStart = c['clip_start_sec']\n",
    "        videoEnd = c['clip_end_sec']\n",
    "        if mq_dataset_val.clip_video[_id] not in ego4D.videos:\n",
    "            continue\n",
    "        video = ego4D.videos[mq_dataset_val.clip_video[_id]]\n",
    "        audioStart = video['video_metadata']['audio_start_sec']\n",
    "        if video['video_metadata']['audio_duration_sec'] == None:\n",
    "            continue\n",
    "        audioEnd = video['video_metadata']['audio_start_sec'] + video['video_metadata']['audio_duration_sec']\n",
    "        if videoStart >= audioStart and videoStart <= audioEnd and videoEnd >= audioStart and videoEnd <= audioEnd :\n",
    "            clipAudio_mq_val.add(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.clips.keys()), len(nql_dataset_val.clips.keys()), len(clipAudio_nlq_train),len(clipAudio_nlq_val) )\n",
    "print(len(vq_dataset_train.clips.keys()), len(vq_dataset_val.clips.keys()), len(clipAudio_vq_train), len(clipAudio_vq_val))\n",
    "print(len(mq_dataset_train.clips.keys()), len(mq_dataset_val.clips.keys()), len(clipAudio_mq_train), len(clipAudio_mq_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_nql_train = set()\n",
    "for _id in clipAudio_nlq_train:\n",
    "    video_ids_nql_train.add(nql_dataset_train.clip_video[_id])\n",
    "\n",
    "video_ids_nql_val = set()\n",
    "for _id in clipAudio_nlq_val:\n",
    "    video_ids_nql_val.add(nql_dataset_val.clip_video[_id])\n",
    "    \n",
    "video_ids_vq_train = set()\n",
    "for _id in clipAudio_vq_train:\n",
    "    video_ids_vq_train.add(vq_dataset_train.clip_video[_id])\n",
    "    \n",
    "video_ids_vq_val = set()\n",
    "for _id in clipAudio_vq_val:\n",
    "    video_ids_vq_val.add(vq_dataset_val.clip_video[_id])\n",
    "    \n",
    "video_ids_mq_train = set()\n",
    "for _id in clipAudio_mq_train:\n",
    "    video_ids_mq_train.add(mq_dataset_train.clip_video[_id])\n",
    "    \n",
    "video_ids_mq_val = set()\n",
    "for _id in clipAudio_mq_val:\n",
    "    video_ids_mq_val.add(mq_dataset_val.clip_video[_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nql_dataset_train.videos.keys()),len(nql_dataset_val.videos.keys()),len(vq_dataset_train.videos.keys()),len(vq_dataset_val.videos.keys()),len(mq_dataset_train.videos.keys()),len(mq_dataset_val.videos.keys()))\n",
    "print(len(video_ids_nql_train),len(video_ids_nql_val),len(video_ids_vq_train),len(video_ids_vq_val),len(video_ids_mq_train),len(video_ids_mq_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ba669",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_union = video_ids_nql_train.union(video_ids_nql_val)\n",
    "vq_union = video_ids_vq_train.union(video_ids_vq_val)\n",
    "mq_union = video_ids_mq_train.union(video_ids_mq_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nlq_union), len(vq_union),len(mq_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d85c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlq_vq_mq = nlq_union.intersection(vq_union.intersection(mq_union))\n",
    "len(nlq_vq_mq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_nql_union = clipAudio_nlq_train.union(clipAudio_nlq_val)\n",
    "clip_vq_union = clipAudio_vq_train.union(clipAudio_vq_val)\n",
    "clip_mq_union = clipAudio_mq_train.union(clipAudio_mq_val)\n",
    "print(len(clip_nql_union), len(clip_vq_union), len(clip_mq_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_nlq_vq_mq = clip_nql_union.union(clip_vq_union.union(clip_mq_union))\n",
    "len(clip_nlq_vq_mq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips = defaultdict(set)\n",
    "for _id in clipAudio_nlq_train:\n",
    "    idx = nql_dataset_train.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_nlq_val:\n",
    "    idx = nql_dataset_val.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_vq_train:\n",
    "    idx = vq_dataset_train.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_vq_val:\n",
    "    idx = vq_dataset_val.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "\n",
    "for _id in clipAudio_mq_train:\n",
    "    idx = mq_dataset_train.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)\n",
    "    \n",
    "for _id in clipAudio_mq_val:\n",
    "    idx = mq_dataset_val.clip_video[_id]\n",
    "    if idx in nlq_vq_mq:\n",
    "        video_clips[idx].add(_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3680cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips_df = pd.DataFrame.from_dict(video_clips.items())\n",
    "video_clips_df['Length'] = video_clips_df[1].str.len()\n",
    "video_clips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = video_clips_df.plot.bar( y='Length', rot=0, figsize=(30, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips_3 = video_clips_df[video_clips_df['Length'] <= 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18624bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ''\n",
    "for i, s in enumerate(sameavlen_nlq_vq_mq_intersection):\n",
    "    ids += s\n",
    "    if i!= (len(sameavlen_nlq_vq_mq_intersection)-1):\n",
    "        ids += ' '\n",
    "for i, c in enumerate(video_clips_3[1]):\n",
    "    for j, _id in enumerate(c):\n",
    "        ids += _id\n",
    "        if i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"./less_3.txt\",\"w\")\n",
    "file1.write(ids)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with av.open(clips_path) as input_video:\n",
    "    stream = input_video.streams.audio\n",
    "    print(stream)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd145cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_path = v1_root + 'clips/1c6f2ab7-1088-45d6-b172-8bbd2ded74ac.mp4'\n",
    "my_clip = mp.VideoFileClip(clips_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clip.audio.write_audiofile(r\"my_result.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd59823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68be5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = defaultdict(str)\n",
    "for root, dirs, files in os.walk(\"./dataset/tmp/v1/clips/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            file_paths[file.split('.')[0]] = os.path.join(root, file)\n",
    "            \n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b96ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "MoviePy couldn't find the codec associated with the filename. Provide the 'codec' parameter in write_audiofile.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs682/lib/python3.8/site-packages/moviepy/audio/AudioClip.py:200\u001b[0m, in \u001b[0;36mAudioClip.write_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     codec \u001b[38;5;241m=\u001b[39m \u001b[43mextensions_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mext\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextractAudioFromClips\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Data/research/ego4d/utils.py:23\u001b[0m, in \u001b[0;36mextractAudioFromClips\u001b[0;34m(video_path, audio_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _filename, _path \u001b[38;5;129;01min\u001b[39;00m file_paths\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     22\u001b[0m     _clip \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mVideoFileClip(_path)\n\u001b[0;32m---> 23\u001b[0m     \u001b[43m_clip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_audiofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-62>:2\u001b[0m, in \u001b[0;36mwrite_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs682/lib/python3.8/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs682/lib/python3.8/site-packages/moviepy/audio/AudioClip.py:202\u001b[0m, in \u001b[0;36mAudioClip.write_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n\u001b[1;32m    200\u001b[0m         codec \u001b[38;5;241m=\u001b[39m extensions_dict[ext[\u001b[38;5;241m1\u001b[39m:]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoviePy couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find the codec associated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the filename. Provide the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter in write_audiofile.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ffmpeg_audiowrite(\u001b[38;5;28mself\u001b[39m, filename, fps, nbytes, buffersize,\n\u001b[1;32m    207\u001b[0m                          codec\u001b[38;5;241m=\u001b[39mcodec, bitrate\u001b[38;5;241m=\u001b[39mbitrate,\n\u001b[1;32m    208\u001b[0m                          write_logfile\u001b[38;5;241m=\u001b[39mwrite_logfile, verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    209\u001b[0m                          ffmpeg_params\u001b[38;5;241m=\u001b[39mffmpeg_params,\n\u001b[1;32m    210\u001b[0m                          logger\u001b[38;5;241m=\u001b[39mlogger)\n",
      "\u001b[0;31mValueError\u001b[0m: MoviePy couldn't find the codec associated with the filename. Provide the 'codec' parameter in write_audiofile."
     ]
    }
   ],
   "source": [
    "extractAudioFromClips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7245ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
